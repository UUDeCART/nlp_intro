{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note : This notebook was prepared for a previous NLP course by Brian Chapman, Wendy Chapman, Jianlin Shi and Danielle Mowery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical natural language processing\n",
    "\n",
    "Clinical texts contain a summary of the patient's clinical story and their physiological status changes over time. Specifically, members of the care providing team document these changes by describing the patient's status upon admission, during examination, throughout their treatment, and upon discharge/transfer. What kinds of secondary use (beyond patient care) could be supported from information extracted from textual data e.g., clinical reports?\n",
    "\n",
    "* Recruit patients for clinical trials\n",
    "* Enrich structured problem lists with missed problems\n",
    "* Build cohorts for comparative effectiveness studies\n",
    "* Extract a patient's family history information for assessing predisposition of disease\n",
    "\n",
    "\n",
    "Below is a sample report from <a href=http://www.mtsamples.com/site/pages/sample.asp?Type=91-SOAP%20/%20Chart%20/%20Progress%20Notes&Sample=40-Cardiology%20Progress%20Note>\"MTSamples.com\"</a>\n",
    "\n",
    "![MTSamples.com](./images/MT_Samples_report.png)\n",
    "\n",
    "From the report above, how would you tell me whether the patient has had chest pain? What information did you use to induce that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing textual reports\n",
    "\n",
    "What information is described in the report above?\n",
    "* symptoms\n",
    "* signs\n",
    "* tests\n",
    "* treatments\n",
    "\n",
    "What type of structures are used to construct the report?\n",
    "* words\n",
    "* phrases\n",
    "* sentences\n",
    "* sections\n",
    "* SOAP structure\n",
    "\n",
    "How does this report structure differ from other texts e.g., newspaper articles? How is it similar? \n",
    "\n",
    "In this lesson, we are going to learn how to analyze information within reports that can be leveraged to distinguish report types from each other (discharge summary vs radiology reports), classify patients (diseased vs healthy), and other use cases.\n",
    "\n",
    "\n",
    "# Reading in files\n",
    "\n",
    "Again, one of the fundamental steps to processing and analyzing textual reports, is locating files to read into memory. To get started we are going to call in or 'import' some tools that allow us to read in files from the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "print(os.getcwd()+r\"/data/mtsamples_documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reading in texts from the directory\n",
    "\n",
    "Next, we want to read in a set of text files using glob to begin processing them. Glob will return us a list of text files with their corresponding paths.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files=glob.glob(os.getcwd()+\"/data/mtsamples_documents/*.txt\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a file for processing\n",
    "\n",
    "Using the list and indexing, we can select a file containing a progress note report to process. Use the index to select a report of interest to you. We will select the seventh file in the list from the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files[-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening a file for processing\n",
    "\n",
    "Now that we've selected a file to process, we can use 'open' and 'read' to read all the file contents (report) into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_text=open(files[-7]).read()\n",
    "print(report_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting a report \n",
    "\n",
    "One of the fundamental tasks to text processing is segmenting the text into more managable parts e.g., section segmentation or sentence segmentation. For many NLP tasks such as information extraction, a single sentence can contain most information about an entity or event. Using Textblob, we can segment the report into sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#sentence object\n",
    "blob = TextBlob(report_text)\n",
    "\n",
    "for sent in blob.sentences:\n",
    "    print(sent)\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing sentences\n",
    "\n",
    "Because Textblob returns a list, we can also count the number of sentences in the report. How many sentences are there in the report? How might knowing the number of sentences be important to guessing a report type? \n",
    "\n",
    "We can also obtain a particular sentence in the list using the index. What does the 10th sentence read? When could it be important to select a sentence by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(blob.sentences))\n",
    "\n",
    "print(blob.sentences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing sentences into words\n",
    "\n",
    "Words are the basic building blocks of text. As humans, when we want to find relevant information from text we search text for words in sentences of the report related to the topic of interest to us. Textblob supports tokenization by providing the words or tokens from the report text. What's the difference between these two functions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(blob.words[0:50])\n",
    "\n",
    "print(\"=================\")\n",
    "\n",
    "print(blob.tokens[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting words in the text\n",
    "\n",
    "In some cases, knowing the frequency of words in text can help us better understand the content of the text and classify it by topic. For example, if we know a report contains many terms associated with the heart e.g., cardiology, echocardiogram, heart, infarction, we may deduce that the patient may have been seen for cardiovascular problems. If we review patient satisfaction surveys with many positive terms, we may deduce that the patient had a satisfactory visit. Textblob can give us word counts from a report text. Which words are most frequent? Are they always informative? HINT: How frequent is the word 'and'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(blob.word_counts)\n",
    "\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(\"and:\",blob.words.count('and'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding exercise I\n",
    "\n",
    "What are the 5 most frequent words in the dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing multi-words (n-grams)\n",
    "\n",
    "Signs, symptoms, diagnoses are often made from more than one word. In addition to individual words, we can define windows of words with varying lengths of tokens (1-token = unigrams; 2-token = bigrams, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Bigrams:\", blob.ngrams(n=2))\n",
    "print(\"Trigram - right upper extremity:\", blob.ngrams(n=3).count(['right', 'upper', 'extremity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing words to their stems (morphology)\n",
    "\n",
    "Words can have many variants based on parts of speech. Textblob supports lemmatizing words to their root form. This can be important for identifying a concept documented with many lexical variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# before we perform syntactic operations like lemmatization we should make sure that we have some resources available\n",
    "# including WordNet and some taggers\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "w = Word(\"smokes\")\n",
    "print(\"lemma of smokes is:\", w.lemmatize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does a lemmatizer trained on general English work for medical language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging parts of speech (syntax)\n",
    "\n",
    "Signs, symptoms, diagnoses are often nouns. Textblob can give us the parts of speech of words from the text. There are two sets of tags commonly used for part of speech tagging: [Penn Treebank] (https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\") and [Brown Corpus tags] (http://www.comp.leeds.ac.uk/ccalas/tagsets/brown.html) Let's briefly review the different standards for tagging parts of speech of text. Which tag set appears below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(blob.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing noun phrases\n",
    "\n",
    "Not only are signs, symptoms, diagnoses often nouns, but they can be mulit-word and part of noun phrases; therefore, parsing phrases based on part of speech can help us identify words that when grouped together describe a salient clinical concept e.g., 'coronary artery disease' --> ('coronary', 'JJ'), ('artery', 'NN'), ('disease', 'NN') rather than just 'coronary' ('coronary', 'JJ'). What types clinical concepts are most frequently represented by noun phrases in the text? Which seem correct and which don't seem correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(blob.np_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding exercise III\n",
    "\n",
    "Print the noun phrases that occur more than 1 time in the text above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing noun phrases in text\n",
    "\n",
    "Part of speech tags in conjuction with named entity recognition labels can depict how clinical concepts are created from words create phrases and clauses. Can you identify the beginning (B), inside (I) and outside (O) of each phrase? In addition to BIO labelling there are other labels standards. [Take a look!] (https://lingpipe-blog.com/2009/10/14/coding-chunkers-as-taggers-io-bio-bmewo-and-bmewo/) \n",
    "\n",
    "Go here to experiment with parse trees: foxtype.com/sentence-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blob.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining meaning of words (semantics)\n",
    "\n",
    "Words, phrases, and clauses convey meaning or the semantics of text by describing entities and events within clinical text. The meaning of a concept can be derived from a lexicon or dictionary of words.\n",
    "For instance, we can define the concept of Addison’s disease with its synonyms (words sharing similar meaning) e.g.,\n",
    "adrenocortical insufficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vertigo = Word('vertigo')\n",
    "print(\"Vertigo: \",vertigo.definitions)\n",
    "\n",
    "\n",
    "dizziness = Word('dizziness')\n",
    "print(\"Dizziness: \",vertigo.definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words have synonyms, and there are many dictionaries that will provide synonyms. WordNet is the most comprehensive but the least focused on medical words (although it has many medical words). The UMLS Metathesaurus is a thesaurus of thesauri that has synonyms for many medical and biological terms.\n",
    "\n",
    "Check out the synonymize function someone wrote: rwet.decontextualize.com/book/textblob/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob.wordnet import NOUN\n",
    "synsets = dizziness.get_synsets(pos=NOUN)\n",
    "print(synsets[0].lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying many senses of a word\n",
    "\n",
    "In addition to one word being similar to another word, one word can convey many meanings (i.e., a word can be polysemous), e.g., discharge can be release of a patient from care or a substance from an abscess. Discerning the sense or meaning of a word is called word sense disambiguation.  Using Textblob and the underlying dictionary <a href=\"https://wordnet.princeton.edu/wordnet/\">WordNet</a>), we can obtain the definition and corresponding synsets (i.e., word senses) of a word. Are any of the synsets for 'admit' below clinical? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob.wordnet import VERB\n",
    "\n",
    "word = Word('admit')\n",
    "for definition, syn in zip(word.definitions, word.get_synsets(pos=VERB)):\n",
    "    print(definition+\" --> \"+str(syn)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the degree of similarity between synsets of two words\n",
    "\n",
    "Given two words, we can also compare the synsets to determine the degree of semantic similarity. How similar are the pus and discharge synsets below? Can you think of other words with more semantic similarity? Try them! Test different v. of the same word to look for similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob.wordnet import Synset\n",
    "\n",
    "declare_true=Synset('admit.v.01')\n",
    "give_access=Synset('admit.v.05')\n",
    "print(\"Similarity: \", declare_true.path_similarity(give_access))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms\n",
    "Use the same code to see how similar two different words are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "declare_true=Synset('dizziness.n.01')\n",
    "give_access=Synset('vertigo.n.01')\n",
    "print(\"Similarity: \", declare_true.path_similarity(give_access))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
